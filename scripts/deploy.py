#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Auraç”Ÿäº§ç¯å¢ƒéƒ¨ç½²è„šæœ¬
æä¾›Dockerå®¹å™¨åŒ–éƒ¨ç½²ã€ç³»ç»ŸæœåŠ¡å®‰è£…ã€é…ç½®ç®¡ç†ç­‰åŠŸèƒ½
"""

import os
import sys
import argparse
import subprocess
import shutil
import json
import yaml
from pathlib import Path
from typing import Dict, List, Optional
import tempfile
import tarfile

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class AuraDeployer:
    """Auraéƒ¨ç½²ç®¡ç†å™¨"""
    
    def __init__(self):
        self.project_root = project_root
        self.build_dir = project_root / "build"
        self.dist_dir = project_root / "dist"
        
    def run_command(self, command: List[str], cwd: Optional[Path] = None, 
                   check: bool = True) -> subprocess.CompletedProcess:
        """è¿è¡Œå‘½ä»¤"""
        print(f"ğŸ”§ æ‰§è¡Œ: {' '.join(command)}")
        
        result = subprocess.run(
            command,
            cwd=cwd or self.project_root,
            capture_output=True,
            text=True,
            check=check
        )
        
        if result.stdout:
            print(result.stdout)
        if result.stderr:
            print(result.stderr)
        
        return result
    
    def create_dockerfile(self) -> Path:
        """åˆ›å»ºDockerfile"""
        dockerfile_content = """
# Auraæ™ºèƒ½æµè§ˆå™¨è‡ªåŠ¨åŒ–ç³»ç»Ÿ - ç”Ÿäº§ç¯å¢ƒé•œåƒ
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    wget \
    gnupg \
    ca-certificates \
    fonts-liberation \
    libasound2 \
    libatk-bridge2.0-0 \
    libatk1.0-0 \
    libatspi2.0-0 \
    libcups2 \
    libdbus-1-3 \
    libdrm2 \
    libgtk-3-0 \
    libnspr4 \
    libnss3 \
    libwayland-client0 \
    libxcomposite1 \
    libxdamage1 \
    libxfixes3 \
    libxkbcommon0 \
    libxrandr2 \
    xdg-utils \
    libu2f-udev \
    libvulkan1 \
    && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºérootç”¨æˆ·
RUN useradd -m -u 1000 aura && \
    mkdir -p /app/logs /app/data /app/cache && \
    chown -R aura:aura /app

# å¤åˆ¶requirementsæ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å®‰è£…Playwrightæµè§ˆå™¨
RUN playwright install chromium

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY --chown=aura:aura . .

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER aura

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["python", "scripts/start.py", "api", "--env", "production", "--host", "0.0.0.0", "--port", "8000"]
"""
        
        dockerfile_path = self.project_root / "Dockerfile"
        with open(dockerfile_path, "w", encoding="utf-8") as f:
            f.write(dockerfile_content.strip())
        
        print(f"âœ… Dockerfileå·²åˆ›å»º: {dockerfile_path}")
        return dockerfile_path
    
    def create_docker_compose(self) -> Path:
        """åˆ›å»ºdocker-compose.yml"""
        compose_content = """
version: '3.8'

services:
  aura-api:
    build: .
    container_name: aura-api
    ports:
      - "8000:8000"
    environment:
      - AURA_ENV=production
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://aura:aura_password@postgres:5432/aura
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./cache:/app/cache
    depends_on:
      - redis
      - postgres
    restart: unless-stopped
    networks:
      - aura-network
  
  redis:
    image: redis:7-alpine
    container_name: aura-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - aura-network
  
  postgres:
    image: postgres:15-alpine
    container_name: aura-postgres
    environment:
      - POSTGRES_DB=aura
      - POSTGRES_USER=aura
      - POSTGRES_PASSWORD=aura_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - aura-network
  
  nginx:
    image: nginx:alpine
    container_name: aura-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - aura-api
    restart: unless-stopped
    networks:
      - aura-network

volumes:
  redis_data:
  postgres_data:

networks:
  aura-network:
    driver: bridge
"""
        
        compose_path = self.project_root / "docker-compose.yml"
        with open(compose_path, "w", encoding="utf-8") as f:
            f.write(compose_content.strip())
        
        print(f"âœ… docker-compose.ymlå·²åˆ›å»º: {compose_path}")
        return compose_path
    
    def create_nginx_config(self) -> Path:
        """åˆ›å»ºNginxé…ç½®"""
        nginx_content = """
events {
    worker_connections 1024;
}

http {
    upstream aura_api {
        server aura-api:8000;
    }
    
    # é™æµé…ç½®
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    
    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';
    
    server {
        listen 80;
        server_name _;
        
        # é‡å®šå‘åˆ°HTTPS
        return 301 https://$server_name$request_uri;
    }
    
    server {
        listen 443 ssl http2;
        server_name _;
        
        # SSLé…ç½®
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        
        # å®‰å…¨å¤´
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";
        
        # è®¿é—®æ—¥å¿—
        access_log /var/log/nginx/aura_access.log main;
        error_log /var/log/nginx/aura_error.log;
        
        # APIä»£ç†
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            
            proxy_pass http://aura_api;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # WebSocketæ”¯æŒ
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            
            # è¶…æ—¶è®¾ç½®
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }
        
        # é™æ€æ–‡ä»¶
        location /static/ {
            alias /app/static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
        
        # å¥åº·æ£€æŸ¥
        location /health {
            proxy_pass http://aura_api/health;
        }
        
        # é»˜è®¤è·¯ç”±
        location / {
            proxy_pass http://aura_api;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}
"""
        
        nginx_path = self.project_root / "nginx.conf"
        with open(nginx_path, "w", encoding="utf-8") as f:
            f.write(nginx_content.strip())
        
        print(f"âœ… nginx.confå·²åˆ›å»º: {nginx_path}")
        return nginx_path
    
    def create_systemd_service(self) -> Path:
        """åˆ›å»ºsystemdæœåŠ¡æ–‡ä»¶"""
        service_content = f"""
[Unit]
Description=Auraæ™ºèƒ½æµè§ˆå™¨è‡ªåŠ¨åŒ–ç³»ç»Ÿ
After=network.target
Wants=network.target

[Service]
Type=simple
User=aura
Group=aura
WorkingDirectory={self.project_root}
Environment=AURA_ENV=production
Environment=PYTHONPATH={self.project_root}
ExecStart={sys.executable} scripts/start.py full --env production
ExecReload=/bin/kill -HUP $MAINPID
Restart=always
RestartSec=10

# å®‰å…¨è®¾ç½®
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths={self.project_root}/logs {self.project_root}/data {self.project_root}/cache

# èµ„æºé™åˆ¶
LimitNOFILE=65536
LimitNPROC=4096

[Install]
WantedBy=multi-user.target
"""
        
        service_path = self.project_root / "aura.service"
        with open(service_path, "w", encoding="utf-8") as f:
            f.write(service_content.strip())
        
        print(f"âœ… systemdæœåŠ¡æ–‡ä»¶å·²åˆ›å»º: {service_path}")
        return service_path
    
    def create_deployment_config(self, environment: str) -> Path:
        """åˆ›å»ºéƒ¨ç½²é…ç½®"""
        config = {
            "environment": environment,
            "version": "1.0.0",
            "deployment": {
                "method": "docker",  # docker, systemd, manual
                "replicas": 1,
                "resources": {
                    "cpu": "1000m",
                    "memory": "2Gi"
                }
            },
            "database": {
                "host": "localhost",
                "port": 5432,
                "name": "aura",
                "user": "aura"
            },
            "redis": {
                "host": "localhost",
                "port": 6379
            },
            "monitoring": {
                "enabled": True,
                "prometheus_port": 9090,
                "grafana_port": 3000
            },
            "backup": {
                "enabled": True,
                "schedule": "0 2 * * *",  # æ¯å¤©å‡Œæ™¨2ç‚¹
                "retention_days": 30
            }
        }
        
        config_path = self.project_root / f"deploy-{environment}.yaml"
        with open(config_path, "w", encoding="utf-8") as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… éƒ¨ç½²é…ç½®å·²åˆ›å»º: {config_path}")
        return config_path
    
    def build_docker_image(self, tag: str = "aura:latest"):
        """æ„å»ºDockeré•œåƒ"""
        print(f"ğŸ³ æ„å»ºDockeré•œåƒ: {tag}")
        
        # åˆ›å»ºDockerfile
        self.create_dockerfile()
        
        # æ„å»ºé•œåƒ
        self.run_command(["docker", "build", "-t", tag, "."])
        
        print(f"âœ… Dockeré•œåƒæ„å»ºå®Œæˆ: {tag}")
    
    def deploy_docker(self, environment: str = "production"):
        """Dockeréƒ¨ç½²"""
        print(f"ğŸš€ å¼€å§‹Dockeréƒ¨ç½² ({environment})...")
        
        # åˆ›å»ºéƒ¨ç½²æ–‡ä»¶
        self.create_docker_compose()
        self.create_nginx_config()
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        for dir_name in ["logs", "data", "cache", "ssl"]:
            (self.project_root / dir_name).mkdir(exist_ok=True)
        
        # æ„å»ºé•œåƒ
        self.build_docker_image()
        
        # å¯åŠ¨æœåŠ¡
        self.run_command(["docker-compose", "up", "-d"])
        
        print("âœ… Dockeréƒ¨ç½²å®Œæˆ")
        print("ğŸ“ APIåœ°å€: http://localhost:8000")
        print("ğŸ“š APIæ–‡æ¡£: http://localhost:8000/docs")
        print("ğŸ”§ ç®¡ç†å‘½ä»¤:")
        print("  docker-compose logs -f    # æŸ¥çœ‹æ—¥å¿—")
        print("  docker-compose stop       # åœæ­¢æœåŠ¡")
        print("  docker-compose restart    # é‡å¯æœåŠ¡")
    
    def deploy_systemd(self, environment: str = "production"):
        """systemdéƒ¨ç½²"""
        print(f"ğŸ”§ å¼€å§‹systemdéƒ¨ç½² ({environment})...")
        
        # åˆ›å»ºæœåŠ¡æ–‡ä»¶
        service_file = self.create_systemd_service()
        
        # åˆ›å»ºç”¨æˆ·
        try:
            self.run_command(["sudo", "useradd", "-r", "-s", "/bin/false", "aura"], check=False)
        except subprocess.CalledProcessError:
            print("ç”¨æˆ·auraå·²å­˜åœ¨")
        
        # è®¾ç½®æƒé™
        self.run_command(["sudo", "chown", "-R", "aura:aura", str(self.project_root)])
        
        # å®‰è£…æœåŠ¡æ–‡ä»¶
        self.run_command(["sudo", "cp", str(service_file), "/etc/systemd/system/"])
        
        # é‡è½½systemd
        self.run_command(["sudo", "systemctl", "daemon-reload"])
        
        # å¯ç”¨å¹¶å¯åŠ¨æœåŠ¡
        self.run_command(["sudo", "systemctl", "enable", "aura"])
        self.run_command(["sudo", "systemctl", "start", "aura"])
        
        print("âœ… systemdéƒ¨ç½²å®Œæˆ")
        print("ğŸ”§ ç®¡ç†å‘½ä»¤:")
        print("  sudo systemctl status aura    # æŸ¥çœ‹çŠ¶æ€")
        print("  sudo systemctl stop aura      # åœæ­¢æœåŠ¡")
        print("  sudo systemctl restart aura   # é‡å¯æœåŠ¡")
        print("  sudo journalctl -u aura -f    # æŸ¥çœ‹æ—¥å¿—")
    
    def create_backup_script(self) -> Path:
        """åˆ›å»ºå¤‡ä»½è„šæœ¬"""
        backup_content = f"""
#!/bin/bash
# Auraç³»ç»Ÿå¤‡ä»½è„šæœ¬

set -e

BACKUP_DIR="/var/backups/aura"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/aura_backup_$DATE.tar.gz"
RETENTION_DAYS=30

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

echo "å¼€å§‹å¤‡ä»½Auraç³»ç»Ÿ..."

# å¤‡ä»½åº”ç”¨æ•°æ®
tar -czf $BACKUP_FILE \
    -C {self.project_root} \
    --exclude='logs/*' \
    --exclude='cache/*' \
    --exclude='__pycache__' \
    --exclude='.git' \
    .

# å¤‡ä»½æ•°æ®åº“
if command -v pg_dump &> /dev/null; then
    pg_dump -h localhost -U aura aura > $BACKUP_DIR/database_$DATE.sql
    gzip $BACKUP_DIR/database_$DATE.sql
fi

# æ¸…ç†æ—§å¤‡ä»½
find $BACKUP_DIR -name "aura_backup_*.tar.gz" -mtime +$RETENTION_DAYS -delete
find $BACKUP_DIR -name "database_*.sql.gz" -mtime +$RETENTION_DAYS -delete

echo "å¤‡ä»½å®Œæˆ: $BACKUP_FILE"
"""
        
        backup_path = self.project_root / "scripts" / "backup.sh"
        with open(backup_path, "w", encoding="utf-8") as f:
            f.write(backup_content.strip())
        
        # è®¾ç½®æ‰§è¡Œæƒé™
        backup_path.chmod(0o755)
        
        print(f"âœ… å¤‡ä»½è„šæœ¬å·²åˆ›å»º: {backup_path}")
        return backup_path
    
    def create_monitoring_config(self) -> Path:
        """åˆ›å»ºç›‘æ§é…ç½®"""
        prometheus_config = """
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'aura-api'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['localhost:9100']

  - job_name: 'redis'
    static_configs:
      - targets: ['localhost:9121']

  - job_name: 'postgres'
    static_configs:
      - targets: ['localhost:9187']
"""
        
        monitoring_dir = self.project_root / "monitoring"
        monitoring_dir.mkdir(exist_ok=True)
        
        prometheus_path = monitoring_dir / "prometheus.yml"
        with open(prometheus_path, "w", encoding="utf-8") as f:
            f.write(prometheus_config.strip())
        
        print(f"âœ… ç›‘æ§é…ç½®å·²åˆ›å»º: {prometheus_path}")
        return prometheus_path
    
    def package_release(self, version: str) -> Path:
        """æ‰“åŒ…å‘å¸ƒç‰ˆæœ¬"""
        print(f"ğŸ“¦ æ‰“åŒ…å‘å¸ƒç‰ˆæœ¬: {version}")
        
        # åˆ›å»ºæ„å»ºç›®å½•
        self.build_dir.mkdir(exist_ok=True)
        self.dist_dir.mkdir(exist_ok=True)
        
        # æ¸…ç†æ—§æ–‡ä»¶
        for file in self.build_dir.glob("*"):
            if file.is_file():
                file.unlink()
            else:
                shutil.rmtree(file)
        
        # å¤åˆ¶æºä»£ç 
        exclude_patterns = {
            '__pycache__', '.git', '.pytest_cache', 'node_modules',
            'logs', 'cache', 'build', 'dist', '.env*'
        }
        
        for item in self.project_root.iterdir():
            if item.name not in exclude_patterns:
                if item.is_file():
                    shutil.copy2(item, self.build_dir)
                else:
                    shutil.copytree(item, self.build_dir / item.name)
        
        # åˆ›å»ºç‰ˆæœ¬ä¿¡æ¯
        version_info = {
            "version": version,
            "build_date": subprocess.check_output(
                ["date", "-Iseconds"], text=True
            ).strip(),
            "git_commit": subprocess.check_output(
                ["git", "rev-parse", "HEAD"], text=True
            ).strip() if (self.project_root / ".git").exists() else "unknown"
        }
        
        with open(self.build_dir / "version.json", "w") as f:
            json.dump(version_info, f, indent=2)
        
        # åˆ›å»ºå‹ç¼©åŒ…
        archive_name = f"aura-{version}.tar.gz"
        archive_path = self.dist_dir / archive_name
        
        with tarfile.open(archive_path, "w:gz") as tar:
            tar.add(self.build_dir, arcname=f"aura-{version}")
        
        print(f"âœ… å‘å¸ƒåŒ…å·²åˆ›å»º: {archive_path}")
        return archive_path
    
    def health_check(self, url: str = "http://localhost:8000"):
        """å¥åº·æ£€æŸ¥"""
        print(f"ğŸ¥ æ‰§è¡Œå¥åº·æ£€æŸ¥: {url}")
        
        try:
            import requests
            
            # æ£€æŸ¥APIå¥åº·çŠ¶æ€
            response = requests.get(f"{url}/health", timeout=10)
            response.raise_for_status()
            
            health_data = response.json()
            print(f"âœ… APIå¥åº·çŠ¶æ€: {health_data.get('status', 'unknown')}")
            
            # æ£€æŸ¥å„ç»„ä»¶çŠ¶æ€
            for component, status in health_data.get('components', {}).items():
                status_icon = "âœ…" if status == "healthy" else "âŒ"
                print(f"  {status_icon} {component}: {status}")
            
            return True
            
        except Exception as e:
            print(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Auraç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ç®¡ç†å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python scripts/deploy.py docker                    # Dockeréƒ¨ç½²
  python scripts/deploy.py systemd                   # systemdéƒ¨ç½²
  python scripts/deploy.py build --tag aura:v1.0     # æ„å»ºDockeré•œåƒ
  python scripts/deploy.py package --version 1.0.0   # æ‰“åŒ…å‘å¸ƒç‰ˆæœ¬
  python scripts/deploy.py health                     # å¥åº·æ£€æŸ¥
        """
    )
    
    parser.add_argument(
        'command',
        choices=['docker', 'systemd', 'build', 'package', 'health', 'backup'],
        help='éƒ¨ç½²å‘½ä»¤'
    )
    
    parser.add_argument(
        '--environment', '-e',
        choices=['production', 'staging'],
        default='production',
        help='éƒ¨ç½²ç¯å¢ƒ (é»˜è®¤: production)'
    )
    
    parser.add_argument(
        '--tag', '-t',
        default='aura:latest',
        help='Dockeré•œåƒæ ‡ç­¾ (é»˜è®¤: aura:latest)'
    )
    
    parser.add_argument(
        '--version', '-v',
        help='å‘å¸ƒç‰ˆæœ¬å·'
    )
    
    parser.add_argument(
        '--url',
        default='http://localhost:8000',
        help='å¥åº·æ£€æŸ¥URL (é»˜è®¤: http://localhost:8000)'
    )
    
    args = parser.parse_args()
    
    deployer = AuraDeployer()
    
    try:
        if args.command == 'docker':
            deployer.deploy_docker(args.environment)
        
        elif args.command == 'systemd':
            deployer.deploy_systemd(args.environment)
        
        elif args.command == 'build':
            deployer.build_docker_image(args.tag)
        
        elif args.command == 'package':
            if not args.version:
                print("âŒ æ‰“åŒ…å‘½ä»¤éœ€è¦æŒ‡å®šç‰ˆæœ¬å·")
                sys.exit(1)
            deployer.package_release(args.version)
        
        elif args.command == 'health':
            if not deployer.health_check(args.url):
                sys.exit(1)
        
        elif args.command == 'backup':
            deployer.create_backup_script()
        
    except Exception as e:
        print(f"âŒ éƒ¨ç½²å‘½ä»¤å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()