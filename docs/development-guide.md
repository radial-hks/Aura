# å¼€å‘æŒ‡å—

æœ¬æ–‡æ¡£ä¸º Aura é¡¹ç›®çš„å¼€å‘è€…æä¾›è¯¦ç»†çš„å¼€å‘æŒ‡å—ï¼ŒåŒ…æ‹¬ç¯å¢ƒæ­å»ºã€å¼€å‘æµç¨‹ã€è°ƒè¯•æŠ€å·§å’Œæœ€ä½³å®è·µã€‚

## ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [å¼€å‘ç¯å¢ƒæ­å»º](#å¼€å‘ç¯å¢ƒæ­å»º)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [å¼€å‘æµç¨‹](#å¼€å‘æµç¨‹)
- [ä»£ç è§„èŒƒ](#ä»£ç è§„èŒƒ)
- [æµ‹è¯•æŒ‡å—](#æµ‹è¯•æŒ‡å—)
- [è°ƒè¯•æŠ€å·§](#è°ƒè¯•æŠ€å·§)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [è´¡çŒ®æŒ‡å—](#è´¡çŒ®æŒ‡å—)

---

## å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚

- Python 3.9+
- Node.js 16+ (ç”¨äºå‰ç«¯å¼€å‘)
- Git
- Docker (å¯é€‰ï¼Œç”¨äºå®¹å™¨åŒ–éƒ¨ç½²)
- Redis (ç”¨äºç¼“å­˜å’Œæ¶ˆæ¯é˜Ÿåˆ—)
- PostgreSQL (ç”Ÿäº§ç¯å¢ƒæ¨è)

### ä¸€é”®å¯åŠ¨

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/your-org/aura.git
cd aura

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# åˆå§‹åŒ–æ•°æ®åº“
python scripts/init_db.py

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
python main.py --dev
```

### Docker å¿«é€Ÿå¯åŠ¨

```bash
# ä½¿ç”¨ Docker Compose å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f aura-api
```

---

## å¼€å‘ç¯å¢ƒæ­å»º

### 1. Python ç¯å¢ƒ

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

# å‡çº§ pip
pip install --upgrade pip

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt
```

### 2. æ•°æ®åº“è®¾ç½®

#### SQLite (å¼€å‘ç¯å¢ƒ)

```bash
# åˆ›å»ºæ•°æ®åº“
python -c "from src.aura.models.database import create_tables; create_tables()"
```

#### PostgreSQL (ç”Ÿäº§ç¯å¢ƒ)

```bash
# å®‰è£… PostgreSQL
# Ubuntu/Debian
sudo apt-get install postgresql postgresql-contrib

# macOS
brew install postgresql

# åˆ›å»ºæ•°æ®åº“å’Œç”¨æˆ·
sudo -u postgres psql
CREATE DATABASE aura_db;
CREATE USER aura_user WITH PASSWORD 'your_password';
GRANT ALL PRIVILEGES ON DATABASE aura_db TO aura_user;
\q

# è¿è¡Œè¿ç§»
alembic upgrade head
```

### 3. Redis è®¾ç½®

```bash
# å®‰è£… Redis
# Ubuntu/Debian
sudo apt-get install redis-server

# macOS
brew install redis

# å¯åŠ¨ Redis
redis-server

# æµ‹è¯•è¿æ¥
redis-cli ping
```

### 4. MCP æœåŠ¡å™¨è®¾ç½®

```bash
# å®‰è£… Playwright MCP æœåŠ¡å™¨
npm install -g @modelcontextprotocol/server-playwright

# å®‰è£…æµè§ˆå™¨
playwright install

# æµ‹è¯• MCP è¿æ¥
python scripts/test_mcp_connection.py
```

### 5. ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# åº”ç”¨é…ç½®
APP_NAME=Aura
APP_VERSION=1.0.0
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=DEBUG

# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://aura_user:your_password@localhost:5432/aura_db
# æˆ–ä½¿ç”¨ SQLite (å¼€å‘ç¯å¢ƒ)
# DATABASE_URL=sqlite:///./aura.db

# Redis é…ç½®
REDIS_URL=redis://localhost:6379/0

# API é…ç½®
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# å®‰å…¨é…ç½®
SECRET_KEY=your-secret-key-here
JWT_SECRET_KEY=your-jwt-secret-key
ENCRYPTION_KEY=your-encryption-key

# MCP é…ç½®
MCP_SERVERS_CONFIG_PATH=./config/mcp_servers.json

# å¤–éƒ¨æœåŠ¡
OPENAI_API_KEY=your-openai-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key

# ç›‘æ§é…ç½®
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000

# æ–‡ä»¶å­˜å‚¨
FILE_STORAGE_PATH=./storage
MAX_FILE_SIZE=10485760  # 10MB

# ä»»åŠ¡é…ç½®
MAX_CONCURRENT_TASKS=10
TASK_TIMEOUT=300
MAX_RETRY_COUNT=3

# é™æµé…ç½®
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=1000
RATE_LIMIT_WINDOW=3600
```

---

## é¡¹ç›®ç»“æ„

```
aura/
â”œâ”€â”€ .env                        # ç¯å¢ƒå˜é‡
â”œâ”€â”€ .gitignore                  # Git å¿½ç•¥æ–‡ä»¶
â”œâ”€â”€ .pre-commit-config.yaml     # é¢„æäº¤é’©å­
â”œâ”€â”€ docker-compose.yml          # Docker ç¼–æ’
â”œâ”€â”€ Dockerfile                  # Docker é•œåƒ
â”œâ”€â”€ main.py                     # åº”ç”¨å…¥å£
â”œâ”€â”€ requirements.txt            # ç”Ÿäº§ä¾èµ–
â”œâ”€â”€ requirements-dev.txt        # å¼€å‘ä¾èµ–
â”œâ”€â”€ pyproject.toml             # é¡¹ç›®é…ç½®
â”œâ”€â”€ alembic.ini                # æ•°æ®åº“è¿ç§»é…ç½®
â”œâ”€â”€ pytest.ini                # æµ‹è¯•é…ç½®
â”œâ”€â”€ config/                    # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ mcp_servers.json       # MCP æœåŠ¡å™¨é…ç½®
â”‚   â”œâ”€â”€ logging.yaml           # æ—¥å¿—é…ç½®
â”‚   â””â”€â”€ skills/                # æŠ€èƒ½åŒ…é…ç½®
â”œâ”€â”€ docs/                      # æ–‡æ¡£
â”‚   â”œâ”€â”€ system-overview.md     # ç³»ç»Ÿæ¦‚è§ˆ
â”‚   â”œâ”€â”€ architecture-decisions.md # æ¶æ„å†³ç­–
â”‚   â”œâ”€â”€ api-reference.md       # API å‚è€ƒ
â”‚   â”œâ”€â”€ technical-specifications.md # æŠ€æœ¯è§„èŒƒ
â”‚   â”œâ”€â”€ development-guide.md   # å¼€å‘æŒ‡å—
â”‚   â””â”€â”€ deployment-guide.md    # éƒ¨ç½²æŒ‡å—
â”œâ”€â”€ src/                       # æºä»£ç 
â”‚   â””â”€â”€ aura/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ core/              # æ ¸å¿ƒæ¨¡å—
â”‚       â”‚   â”œâ”€â”€ orchestrator.py
â”‚       â”‚   â”œâ”€â”€ action_graph.py
â”‚       â”‚   â””â”€â”€ exceptions.py
â”‚       â”œâ”€â”€ skills/            # æŠ€èƒ½åŒ…æ¨¡å—
â”‚       â”œâ”€â”€ sites/             # ç½‘ç«™æ¨¡å‹æ¨¡å—
â”‚       â”œâ”€â”€ mcp/               # MCP æ¨¡å—
â”‚       â”œâ”€â”€ policy/            # ç­–ç•¥å¼•æ“
â”‚       â”œâ”€â”€ api/               # API æ¨¡å—
â”‚       â”œâ”€â”€ utils/             # å·¥å…·æ¨¡å—
â”‚       â””â”€â”€ models/            # æ•°æ®æ¨¡å‹
â”œâ”€â”€ tests/                     # æµ‹è¯•ä»£ç 
â”‚   â”œâ”€â”€ unit/                  # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ integration/           # é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ e2e/                   # ç«¯åˆ°ç«¯æµ‹è¯•
â”‚   â””â”€â”€ fixtures/              # æµ‹è¯•æ•°æ®
â”œâ”€â”€ scripts/                   # è„šæœ¬å·¥å…·
â”‚   â”œâ”€â”€ init_db.py            # æ•°æ®åº“åˆå§‹åŒ–
â”‚   â”œâ”€â”€ migrate.py            # æ•°æ®è¿ç§»
â”‚   â””â”€â”€ test_mcp_connection.py # MCP è¿æ¥æµ‹è¯•
â”œâ”€â”€ logs/                      # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ storage/                   # æ–‡ä»¶å­˜å‚¨
â””â”€â”€ examples/                  # ç¤ºä¾‹ä»£ç 
    â”œâ”€â”€ basic_usage.py
    â”œâ”€â”€ skill_development.py
    â””â”€â”€ api_client.py
```

---

## å¼€å‘æµç¨‹

### 1. åŠŸèƒ½å¼€å‘æµç¨‹

```mermaid
flowchart TD
    A[åˆ›å»ºåŠŸèƒ½åˆ†æ”¯] --> B[ç¼–å†™ä»£ç ]
    B --> C[ç¼–å†™æµ‹è¯•]
    C --> D[è¿è¡Œæµ‹è¯•]
    D --> E{æµ‹è¯•é€šè¿‡?}
    E -->|å¦| B
    E -->|æ˜¯| F[ä»£ç å®¡æŸ¥]
    F --> G[åˆå¹¶åˆ°ä¸»åˆ†æ”¯]
    G --> H[éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ]
    H --> I[éªŒæ”¶æµ‹è¯•]
    I --> J[éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ]
```

### 2. Git å·¥ä½œæµ

```bash
# 1. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
git checkout -b feature/new-skill-system

# 2. å¼€å‘è¿‡ç¨‹ä¸­å®šæœŸæäº¤
git add .
git commit -m "feat: add skill validation logic"

# 3. æ¨é€åˆ°è¿œç¨‹åˆ†æ”¯
git push origin feature/new-skill-system

# 4. åˆ›å»º Pull Request
# åœ¨ GitHub/GitLab ä¸Šåˆ›å»º PR

# 5. ä»£ç å®¡æŸ¥é€šè¿‡ååˆå¹¶
git checkout main
git pull origin main
git branch -d feature/new-skill-system
```

### 3. æäº¤ä¿¡æ¯è§„èŒƒ

ä½¿ç”¨ [Conventional Commits](https://www.conventionalcommits.org/) è§„èŒƒï¼š

```
<type>[optional scope]: <description>

[optional body]

[optional footer(s)]
```

**ç±»å‹è¯´æ˜ï¼š**
- `feat`: æ–°åŠŸèƒ½
- `fix`: ä¿®å¤ bug
- `docs`: æ–‡æ¡£æ›´æ–°
- `style`: ä»£ç æ ¼å¼åŒ–
- `refactor`: ä»£ç é‡æ„
- `test`: æµ‹è¯•ç›¸å…³
- `chore`: æ„å»ºè¿‡ç¨‹æˆ–è¾…åŠ©å·¥å…·çš„å˜åŠ¨

**ç¤ºä¾‹ï¼š**
```bash
git commit -m "feat(orchestrator): add task priority queue"
git commit -m "fix(mcp): handle connection timeout gracefully"
git commit -m "docs: update API documentation"
```

---

## ä»£ç è§„èŒƒ

### 1. Python ä»£ç è§„èŒƒ

ä½¿ç”¨ä»¥ä¸‹å·¥å…·ç¡®ä¿ä»£ç è´¨é‡ï¼š

```bash
# å®‰è£…ä»£ç è´¨é‡å·¥å…·
pip install black isort flake8 mypy pre-commit

# ä»£ç æ ¼å¼åŒ–
black src/ tests/

# å¯¼å…¥æ’åº
isort src/ tests/

# ä»£ç æ£€æŸ¥
flake8 src/ tests/

# ç±»å‹æ£€æŸ¥
mypy src/
```

### 2. é¢„æäº¤é’©å­

åˆ›å»º `.pre-commit-config.yaml`ï¼š

```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
  
  - repo: https://github.com/psf/black
    rev: 23.1.0
    hooks:
      - id: black
        language_version: python3.9
  
  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        args: ["--profile", "black"]
  
  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
        args: ["--max-line-length=88", "--extend-ignore=E203,W503"]
  
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.0.1
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
```

å®‰è£…é¢„æäº¤é’©å­ï¼š

```bash
pre-commit install
```

### 3. ä»£ç å®¡æŸ¥æ¸…å•

- [ ] ä»£ç ç¬¦åˆé¡¹ç›®ç¼–ç è§„èŒƒ
- [ ] åŒ…å«é€‚å½“çš„ç±»å‹æ³¨è§£
- [ ] æœ‰å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²
- [ ] åŒ…å«ç›¸åº”çš„å•å…ƒæµ‹è¯•
- [ ] æµ‹è¯•è¦†ç›–ç‡è¾¾åˆ°è¦æ±‚
- [ ] æ²¡æœ‰å®‰å…¨æ¼æ´
- [ ] æ€§èƒ½å½±å“å¯æ¥å—
- [ ] å‘åå…¼å®¹æ€§è€ƒè™‘
- [ ] é”™è¯¯å¤„ç†å®Œå–„
- [ ] æ—¥å¿—è®°å½•é€‚å½“

---

## æµ‹è¯•æŒ‡å—

### 1. æµ‹è¯•ç»“æ„

```
tests/
â”œâ”€â”€ unit/                      # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_orchestrator.py   # ç¼–æ’å™¨æµ‹è¯•
â”‚   â”œâ”€â”€ test_action_graph.py   # åŠ¨ä½œå›¾æµ‹è¯•
â”‚   â”œâ”€â”€ test_skill_library.py  # æŠ€èƒ½åº“æµ‹è¯•
â”‚   â””â”€â”€ test_mcp_manager.py    # MCP ç®¡ç†å™¨æµ‹è¯•
â”œâ”€â”€ integration/               # é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ test_api_endpoints.py  # API ç«¯ç‚¹æµ‹è¯•
â”‚   â”œâ”€â”€ test_database.py       # æ•°æ®åº“æµ‹è¯•
â”‚   â””â”€â”€ test_mcp_integration.py # MCP é›†æˆæµ‹è¯•
â”œâ”€â”€ e2e/                       # ç«¯åˆ°ç«¯æµ‹è¯•
â”‚   â”œâ”€â”€ test_user_workflows.py # ç”¨æˆ·å·¥ä½œæµæµ‹è¯•
â”‚   â””â”€â”€ test_skill_execution.py # æŠ€èƒ½æ‰§è¡Œæµ‹è¯•
â”œâ”€â”€ performance/               # æ€§èƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ test_load.py          # è´Ÿè½½æµ‹è¯•
â”‚   â””â”€â”€ test_stress.py        # å‹åŠ›æµ‹è¯•
â”œâ”€â”€ fixtures/                  # æµ‹è¯•æ•°æ®
â”‚   â”œâ”€â”€ sample_tasks.json     # ç¤ºä¾‹ä»»åŠ¡
â”‚   â”œâ”€â”€ sample_skills.json    # ç¤ºä¾‹æŠ€èƒ½
â”‚   â””â”€â”€ sample_sites.json     # ç¤ºä¾‹ç½‘ç«™æ¨¡å‹
â””â”€â”€ conftest.py               # pytest é…ç½®
```

### 2. è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/unit/test_orchestrator.py

# è¿è¡Œç‰¹å®šæµ‹è¯•å‡½æ•°
pytest tests/unit/test_orchestrator.py::test_create_task

# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=src/aura --cov-report=html

# è¿è¡Œæµ‹è¯•å¹¶æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
pytest -v

# è¿è¡Œæµ‹è¯•å¹¶åœ¨ç¬¬ä¸€ä¸ªå¤±è´¥æ—¶åœæ­¢
pytest -x

# è¿è¡Œæ ‡è®°çš„æµ‹è¯•
pytest -m "not slow"
```

### 3. æµ‹è¯•é…ç½®

`pytest.ini` é…ç½®ï¼š

```ini
[tool:pytest]
minversion = 6.0
addopts = 
    -ra
    --strict-markers
    --strict-config
    --cov=src/aura
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-fail-under=80
testpaths = tests
markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    integration: marks tests as integration tests
    e2e: marks tests as end-to-end tests
    performance: marks tests as performance tests
    unit: marks tests as unit tests
```

### 4. æµ‹è¯•ç¤ºä¾‹

```python
import pytest
import asyncio
from unittest.mock import Mock, AsyncMock, patch
from src.aura.core.orchestrator import Orchestrator, TaskRequest
from src.aura.core.exceptions import TaskExecutionError

class TestOrchestrator:
    """ç¼–æ’å™¨æµ‹è¯•ç±»"""
    
    @pytest.fixture
    async def orchestrator(self):
        """åˆ›å»ºç¼–æ’å™¨å®ä¾‹"""
        # åˆ›å»ºæ¨¡æ‹Ÿä¾èµ–
        skill_library = Mock()
        site_registry = Mock()
        action_engine = Mock()
        policy_engine = Mock()
        mcp_manager = Mock()
        
        orchestrator = Orchestrator(
            skill_library=skill_library,
            site_registry=site_registry,
            action_engine=action_engine,
            policy_engine=policy_engine,
            mcp_manager=mcp_manager
        )
        
        yield orchestrator
        
        # æ¸…ç†èµ„æº
        await orchestrator.cleanup()
    
    @pytest.fixture
    def sample_task_request(self):
        """ç¤ºä¾‹ä»»åŠ¡è¯·æ±‚"""
        return TaskRequest(
            task_id="test_task_123",
            description="æµ‹è¯•ä»»åŠ¡",
            target_url="https://example.com",
            execution_mode="AI_MODE",
            parameters={"username": "test", "password": "test123"}
        )
    
    @pytest.mark.asyncio
    async def test_create_task_success(self, orchestrator, sample_task_request):
        """æµ‹è¯•æˆåŠŸåˆ›å»ºä»»åŠ¡"""
        # æ¨¡æ‹Ÿç­–ç•¥æ£€æŸ¥é€šè¿‡
        orchestrator.policy_engine.evaluate = AsyncMock(
            return_value=Mock(allowed=True)
        )
        
        # æ‰§è¡Œæµ‹è¯•
        task_id = await orchestrator.create_task(sample_task_request)
        
        # éªŒè¯ç»“æœ
        assert task_id == "test_task_123"
        assert sample_task_request.task_id in orchestrator._tasks
        orchestrator.policy_engine.evaluate.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_execute_task_with_retry(self, orchestrator, sample_task_request):
        """æµ‹è¯•ä»»åŠ¡æ‰§è¡Œé‡è¯•æœºåˆ¶"""
        # æ¨¡æ‹Ÿå‰ä¸¤æ¬¡æ‰§è¡Œå¤±è´¥ï¼Œç¬¬ä¸‰æ¬¡æˆåŠŸ
        call_count = 0
        async def mock_execute(*args, **kwargs):
            nonlocal call_count
            call_count += 1
            if call_count < 3:
                raise TaskExecutionError("ä¸´æ—¶é”™è¯¯")
            return {"success": True, "result": "æ‰§è¡ŒæˆåŠŸ"}
        
        orchestrator._execute_task_internal = mock_execute
        
        # æ‰§è¡Œæµ‹è¯•
        result = await orchestrator.execute_task(sample_task_request.task_id)
        
        # éªŒè¯ç»“æœ
        assert result.status == "COMPLETED"
        assert result.result["success"] is True
        assert call_count == 3  # éªŒè¯é‡è¯•äº†3æ¬¡
    
    @pytest.mark.integration
    async def test_full_task_workflow(self, orchestrator, sample_task_request):
        """é›†æˆæµ‹è¯•ï¼šå®Œæ•´ä»»åŠ¡å·¥ä½œæµ"""
        # è¿™æ˜¯ä¸€ä¸ªé›†æˆæµ‹è¯•ï¼Œæµ‹è¯•å®Œæ•´çš„ä»»åŠ¡æ‰§è¡Œæµç¨‹
        with patch('src.aura.mcp.manager.MCPManager') as mock_mcp:
            # é…ç½® MCP ç®¡ç†å™¨æ¨¡æ‹Ÿ
            mock_mcp.return_value.execute_command = AsyncMock(
                return_value={"success": True, "data": "æ¨¡æ‹Ÿç»“æœ"}
            )
            
            # æ‰§è¡Œå®Œæ•´æµç¨‹
            task_id = await orchestrator.create_task(sample_task_request)
            result = await orchestrator.execute_task(task_id)
            
            # éªŒè¯ç»“æœ
            assert result.status == "COMPLETED"
            assert "data" in result.result

# æ€§èƒ½æµ‹è¯•ç¤ºä¾‹
class TestPerformance:
    """æ€§èƒ½æµ‹è¯•ç±»"""
    
    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_concurrent_task_execution(self):
        """æµ‹è¯•å¹¶å‘ä»»åŠ¡æ‰§è¡Œæ€§èƒ½"""
        import time
        from concurrent.futures import ThreadPoolExecutor
        
        # åˆ›å»ºå¤šä¸ªä»»åŠ¡
        tasks = []
        for i in range(50):
            task = TaskRequest(
                task_id=f"perf_task_{i}",
                description=f"æ€§èƒ½æµ‹è¯•ä»»åŠ¡ {i}",
                target_url="https://httpbin.org/delay/1",
                execution_mode="SCRIPT_MODE",
                parameters={}
            )
            tasks.append(task)
        
        # æµ‹è¯•å¹¶å‘æ‰§è¡Œ
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(self._execute_task, task) for task in tasks]
            results = [future.result() for future in futures]
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        # éªŒè¯æ€§èƒ½è¦æ±‚
        assert len(results) == 50
        assert execution_time < 30  # 50ä¸ªä»»åŠ¡åº”åœ¨30ç§’å†…å®Œæˆ
        
        # è®¡ç®—ååé‡
        throughput = len(results) / execution_time
        assert throughput > 1.5  # ååé‡åº”å¤§äº1.5 tasks/second
    
    def _execute_task(self, task):
        """æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ"""
        import time
        time.sleep(0.5)  # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œæ—¶é—´
        return {"task_id": task.task_id, "status": "completed"}
```

---

## è°ƒè¯•æŠ€å·§

### 1. æ—¥å¿—è°ƒè¯•

```python
import structlog

# é…ç½®ç»“æ„åŒ–æ—¥å¿—
logger = structlog.get_logger(__name__)

# åœ¨ä»£ç ä¸­æ·»åŠ è°ƒè¯•æ—¥å¿—
logger.debug("å¼€å§‹æ‰§è¡Œä»»åŠ¡", task_id=task_id, parameters=parameters)
logger.info("ä»»åŠ¡æ‰§è¡Œå®Œæˆ", task_id=task_id, execution_time=execution_time)
logger.error("ä»»åŠ¡æ‰§è¡Œå¤±è´¥", task_id=task_id, error=str(e))
```

### 2. æ–­ç‚¹è°ƒè¯•

```python
# ä½¿ç”¨ pdb è¿›è¡Œè°ƒè¯•
import pdb; pdb.set_trace()

# æˆ–ä½¿ç”¨ ipdb (æ›´å‹å¥½çš„ç•Œé¢)
import ipdb; ipdb.set_trace()

# åœ¨ pytest ä¸­ä½¿ç”¨æ–­ç‚¹
pytest --pdb  # åœ¨æµ‹è¯•å¤±è´¥æ—¶è¿›å…¥è°ƒè¯•å™¨
pytest --pdbcls=IPython.terminal.debugger:Pdb  # ä½¿ç”¨ IPython è°ƒè¯•å™¨
```

### 3. è¿œç¨‹è°ƒè¯•

```python
# ä½¿ç”¨ debugpy è¿›è¡Œè¿œç¨‹è°ƒè¯•
import debugpy

# å¯åŠ¨è°ƒè¯•æœåŠ¡å™¨
debugpy.listen(("0.0.0.0", 5678))
print("ç­‰å¾…è°ƒè¯•å™¨è¿æ¥...")
debugpy.wait_for_client()
```

### 4. æ€§èƒ½åˆ†æ

```python
# ä½¿ç”¨ cProfile è¿›è¡Œæ€§èƒ½åˆ†æ
import cProfile
import pstats

def profile_function():
    # ä½ çš„ä»£ç 
    pass

# è¿è¡Œæ€§èƒ½åˆ†æ
cProfile.run('profile_function()', 'profile_stats')

# æŸ¥çœ‹ç»“æœ
stats = pstats.Stats('profile_stats')
stats.sort_stats('cumulative')
stats.print_stats(10)
```

### 5. å†…å­˜åˆ†æ

```python
# ä½¿ç”¨ memory_profiler è¿›è¡Œå†…å­˜åˆ†æ
from memory_profiler import profile

@profile
def memory_intensive_function():
    # ä½ çš„ä»£ç 
    pass

# è¿è¡Œåˆ†æ
# python -m memory_profiler your_script.py
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. æ•°æ®åº“ä¼˜åŒ–

```python
# ä½¿ç”¨è¿æ¥æ± 
from sqlalchemy.pool import QueuePool

engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=20,
    max_overflow=30,
    pool_pre_ping=True
)

# ä½¿ç”¨ç´¢å¼•
class Task(Base):
    __tablename__ = 'tasks'
    
    id = Column(UUID, primary_key=True)
    status = Column(String(20), index=True)  # æ·»åŠ ç´¢å¼•
    created_at = Column(DateTime, index=True)  # æ·»åŠ ç´¢å¼•
    
    # å¤åˆç´¢å¼•
    __table_args__ = (
        Index('idx_status_created', 'status', 'created_at'),
    )

# ä½¿ç”¨æ‰¹é‡æ“ä½œ
async def bulk_insert_tasks(tasks: List[Task]):
    async with async_session() as session:
        session.add_all(tasks)
        await session.commit()
```

### 2. ç¼“å­˜ä¼˜åŒ–

```python
from functools import lru_cache
from cachetools import TTLCache
import asyncio

# ä½¿ç”¨ LRU ç¼“å­˜
@lru_cache(maxsize=1000)
def get_site_model(domain: str):
    # è·å–ç½‘ç«™æ¨¡å‹çš„é€»è¾‘
    pass

# ä½¿ç”¨ TTL ç¼“å­˜
cache = TTLCache(maxsize=1000, ttl=300)  # 5åˆ†é’Ÿè¿‡æœŸ

# å¼‚æ­¥ç¼“å­˜è£…é¥°å™¨
def async_cache(ttl=300):
    cache = {}
    
    def decorator(func):
        async def wrapper(*args, **kwargs):
            key = str(args) + str(kwargs)
            if key in cache:
                result, timestamp = cache[key]
                if time.time() - timestamp < ttl:
                    return result
            
            result = await func(*args, **kwargs)
            cache[key] = (result, time.time())
            return result
        return wrapper
    return decorator

@async_cache(ttl=600)
async def get_expensive_data(param):
    # è€—æ—¶æ“ä½œ
    await asyncio.sleep(1)
    return f"result for {param}"
```

### 3. å¼‚æ­¥ä¼˜åŒ–

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

# ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
class AsyncResourceManager:
    async def __aenter__(self):
        self.resource = await acquire_resource()
        return self.resource
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await release_resource(self.resource)

# å¹¶å‘æ‰§è¡Œ
async def process_tasks_concurrently(tasks):
    semaphore = asyncio.Semaphore(10)  # é™åˆ¶å¹¶å‘æ•°
    
    async def process_with_semaphore(task):
        async with semaphore:
            return await process_task(task)
    
    results = await asyncio.gather(
        *[process_with_semaphore(task) for task in tasks],
        return_exceptions=True
    )
    return results

# CPU å¯†é›†å‹ä»»åŠ¡ä½¿ç”¨çº¿ç¨‹æ± 
executor = ThreadPoolExecutor(max_workers=4)

async def cpu_intensive_task(data):
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(executor, process_data, data)
    return result
```

---

## æ•…éšœæ’é™¤

### 1. å¸¸è§é—®é¢˜

#### æ•°æ®åº“è¿æ¥é—®é¢˜

```bash
# æ£€æŸ¥æ•°æ®åº“è¿æ¥
psql -h localhost -U aura_user -d aura_db

# æ£€æŸ¥è¿æ¥æ± çŠ¶æ€
SELECT * FROM pg_stat_activity WHERE datname = 'aura_db';
```

#### Redis è¿æ¥é—®é¢˜

```bash
# æ£€æŸ¥ Redis çŠ¶æ€
redis-cli ping

# æŸ¥çœ‹ Redis ä¿¡æ¯
redis-cli info

# ç›‘æ§ Redis å‘½ä»¤
redis-cli monitor
```

#### MCP è¿æ¥é—®é¢˜

```python
# æµ‹è¯• MCP è¿æ¥
python scripts/test_mcp_connection.py

# æ£€æŸ¥ MCP æœåŠ¡å™¨çŠ¶æ€
curl -X GET http://localhost:8000/api/v1/mcp/servers
```

### 2. æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f logs/aura.log

# è¿‡æ»¤é”™è¯¯æ—¥å¿—
grep "ERROR" logs/aura.log

# åˆ†æè®¿é—®æ—¥å¿—
awk '{print $1}' logs/access.log | sort | uniq -c | sort -nr
```

### 3. æ€§èƒ½ç›‘æ§

```python
# æ·»åŠ æ€§èƒ½ç›‘æ§ä¸­é—´ä»¶
from time import time
from starlette.middleware.base import BaseHTTPMiddleware

class PerformanceMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        start_time = time()
        response = await call_next(request)
        process_time = time() - start_time
        
        response.headers["X-Process-Time"] = str(process_time)
        
        # è®°å½•æ…¢è¯·æ±‚
        if process_time > 1.0:
            logger.warning(
                "æ…¢è¯·æ±‚æ£€æµ‹",
                path=request.url.path,
                method=request.method,
                process_time=process_time
            )
        
        return response
```

### 4. å¥åº·æ£€æŸ¥

```python
# å¥åº·æ£€æŸ¥ç«¯ç‚¹
from fastapi import APIRouter, HTTPException

health_router = APIRouter()

@health_router.get("/health")
async def health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    checks = {
        "database": await check_database(),
        "redis": await check_redis(),
        "mcp_servers": await check_mcp_servers(),
        "disk_space": check_disk_space(),
        "memory": check_memory_usage()
    }
    
    all_healthy = all(checks.values())
    status_code = 200 if all_healthy else 503
    
    return {
        "status": "healthy" if all_healthy else "unhealthy",
        "checks": checks,
        "timestamp": datetime.now().isoformat()
    }

async def check_database():
    """æ£€æŸ¥æ•°æ®åº“è¿æ¥"""
    try:
        async with async_session() as session:
            await session.execute(text("SELECT 1"))
        return True
    except Exception:
        return False

async def check_redis():
    """æ£€æŸ¥ Redis è¿æ¥"""
    try:
        redis_client = get_redis_client()
        await redis_client.ping()
        return True
    except Exception:
        return False
```

---

## è´¡çŒ®æŒ‡å—

### 1. è´¡çŒ®æµç¨‹

1. **Fork é¡¹ç›®**ï¼šåœ¨ GitHub ä¸Š fork é¡¹ç›®åˆ°ä½ çš„è´¦æˆ·
2. **åˆ›å»ºåˆ†æ”¯**ï¼š`git checkout -b feature/your-feature-name`
3. **å¼€å‘åŠŸèƒ½**ï¼šæŒ‰ç…§ä»£ç è§„èŒƒå¼€å‘æ–°åŠŸèƒ½
4. **ç¼–å†™æµ‹è¯•**ï¼šä¸ºæ–°åŠŸèƒ½ç¼–å†™ç›¸åº”çš„æµ‹è¯•
5. **è¿è¡Œæµ‹è¯•**ï¼šç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡
6. **æäº¤ä»£ç **ï¼šä½¿ç”¨è§„èŒƒçš„æäº¤ä¿¡æ¯
7. **åˆ›å»º PR**ï¼šåœ¨ GitHub ä¸Šåˆ›å»º Pull Request
8. **ä»£ç å®¡æŸ¥**ï¼šç­‰å¾…ç»´æŠ¤è€…å®¡æŸ¥ä»£ç 
9. **åˆå¹¶ä»£ç **ï¼šå®¡æŸ¥é€šè¿‡ååˆå¹¶åˆ°ä¸»åˆ†æ”¯

### 2. ä»£ç è´¡çŒ®è¦æ±‚

- [ ] éµå¾ªé¡¹ç›®ç¼–ç è§„èŒƒ
- [ ] åŒ…å«å®Œæ•´çš„ç±»å‹æ³¨è§£
- [ ] æœ‰è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
- [ ] åŒ…å«ç›¸åº”çš„å•å…ƒæµ‹è¯•
- [ ] æµ‹è¯•è¦†ç›–ç‡ä¸ä½äº 80%
- [ ] é€šè¿‡æ‰€æœ‰ CI æ£€æŸ¥
- [ ] æ›´æ–°ç›¸å…³æ–‡æ¡£

### 3. æ–‡æ¡£è´¡çŒ®

- ä¿®å¤æ–‡æ¡£ä¸­çš„é”™è¯¯
- æ·»åŠ ç¼ºå¤±çš„æ–‡æ¡£
- æ”¹è¿›æ–‡æ¡£çš„å¯è¯»æ€§
- ç¿»è¯‘æ–‡æ¡£åˆ°å…¶ä»–è¯­è¨€
- æ·»åŠ ä½¿ç”¨ç¤ºä¾‹

### 4. Bug æŠ¥å‘Š

ä½¿ç”¨ä»¥ä¸‹æ¨¡æ¿æŠ¥å‘Š Bugï¼š

```markdown
## Bug æè¿°
ç®€è¦æè¿°é‡åˆ°çš„é—®é¢˜

## å¤ç°æ­¥éª¤
1. æ‰§è¡Œæ­¥éª¤ 1
2. æ‰§è¡Œæ­¥éª¤ 2
3. çœ‹åˆ°é”™è¯¯

## æœŸæœ›è¡Œä¸º
æè¿°ä½ æœŸæœ›å‘ç”Ÿçš„è¡Œä¸º

## å®é™…è¡Œä¸º
æè¿°å®é™…å‘ç”Ÿçš„è¡Œä¸º

## ç¯å¢ƒä¿¡æ¯
- OS: [e.g. Ubuntu 20.04]
- Python: [e.g. 3.9.7]
- Aura: [e.g. 1.0.0]

## é™„åŠ ä¿¡æ¯
æ·»åŠ ä»»ä½•å…¶ä»–æœ‰åŠ©äºè§£å†³é—®é¢˜çš„ä¿¡æ¯
```

### 5. åŠŸèƒ½è¯·æ±‚

ä½¿ç”¨ä»¥ä¸‹æ¨¡æ¿è¯·æ±‚æ–°åŠŸèƒ½ï¼š

```markdown
## åŠŸèƒ½æè¿°
ç®€è¦æè¿°ä½ å¸Œæœ›æ·»åŠ çš„åŠŸèƒ½

## ä½¿ç”¨åœºæ™¯
æè¿°è¿™ä¸ªåŠŸèƒ½çš„ä½¿ç”¨åœºæ™¯å’Œä»·å€¼

## è¯¦ç»†è®¾è®¡
å¦‚æœæœ‰çš„è¯ï¼Œæè¿°åŠŸèƒ½çš„è¯¦ç»†è®¾è®¡

## æ›¿ä»£æ–¹æ¡ˆ
æè¿°ä½ è€ƒè™‘è¿‡çš„å…¶ä»–è§£å†³æ–¹æ¡ˆ

## é™„åŠ ä¿¡æ¯
æ·»åŠ ä»»ä½•å…¶ä»–ç›¸å…³ä¿¡æ¯
```

---

## å¼€å‘å·¥å…·æ¨è

### 1. IDE é…ç½®

#### VS Code

æ¨èæ’ä»¶ï¼š
- Python
- Pylance
- Python Docstring Generator
- GitLens
- Docker
- REST Client

é…ç½®æ–‡ä»¶ `.vscode/settings.json`ï¼š

```json
{
    "python.defaultInterpreterPath": "./venv/bin/python",
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.formatting.provider": "black",
    "python.sortImports.args": ["--profile", "black"],
    "editor.formatOnSave": true,
    "editor.codeActionsOnSave": {
        "source.organizeImports": true
    },
    "python.testing.pytestEnabled": true,
    "python.testing.pytestArgs": [
        "tests"
    ]
}
```

#### PyCharm

é…ç½®è¦ç‚¹ï¼š
- è®¾ç½® Python è§£é‡Šå™¨ä¸ºè™šæ‹Ÿç¯å¢ƒ
- é…ç½®ä»£ç æ ¼å¼åŒ–å·¥å…·ï¼ˆBlackï¼‰
- å¯ç”¨ç±»å‹æ£€æŸ¥ï¼ˆMyPyï¼‰
- é…ç½®æµ‹è¯•è¿è¡Œå™¨ï¼ˆpytestï¼‰

### 2. å‘½ä»¤è¡Œå·¥å…·

```bash
# å®‰è£…æœ‰ç”¨çš„å‘½ä»¤è¡Œå·¥å…·
pip install rich  # ç¾åŒ–ç»ˆç«¯è¾“å‡º
pip install httpie  # HTTP å®¢æˆ·ç«¯
pip install jq  # JSON å¤„ç†

# ä½¿ç”¨ rich ç¾åŒ–è¾“å‡º
python -m rich.console "Hello, [bold red]World[/bold red]!"

# ä½¿ç”¨ httpie æµ‹è¯• API
http GET localhost:8000/api/v1/tasks Authorization:"Bearer token"

# ä½¿ç”¨ jq å¤„ç† JSON
curl -s localhost:8000/api/v1/tasks | jq '.data[] | .task_id'
```

### 3. æ•°æ®åº“å·¥å…·

- **pgAdmin**: PostgreSQL ç®¡ç†å·¥å…·
- **Redis Desktop Manager**: Redis å¯è§†åŒ–å·¥å…·
- **DBeaver**: é€šç”¨æ•°æ®åº“å·¥å…·

---

> ğŸ“– **ç›¸å…³æ–‡æ¡£**
> - [ç³»ç»Ÿæ¦‚è§ˆ](./system-overview.md)
> - [APIå‚è€ƒæ–‡æ¡£](./api-reference.md)
> - [æŠ€æœ¯è§„èŒƒ](./technical-specifications.md)
> - [éƒ¨ç½²æŒ‡å—](./deployment-guide.md)

---

## è·å–å¸®åŠ©

å¦‚æœåœ¨å¼€å‘è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–å¸®åŠ©ï¼š

- ğŸ“– æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£
- ğŸ› åœ¨ GitHub ä¸Šåˆ›å»º Issue
- ğŸ’¬ åŠ å…¥å¼€å‘è€…è®¨è®ºç¾¤
- ğŸ“§ å‘é€é‚®ä»¶åˆ° dev@aura-project.com
- ğŸ” æœç´¢å·²æœ‰çš„ Issue å’Œ PR

è®°ä½ï¼Œå¥½çš„é—®é¢˜æè¿°èƒ½å¸®åŠ©ä½ æ›´å¿«åœ°å¾—åˆ°å¸®åŠ©ï¼